{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1wyFCQgrqkZLFgOw7z2tpriMgJ9i3p-7w","authorship_tag":"ABX9TyO96N7JR3PczQbxaaMQOH5J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3a564d5f"},"source":["#  Машинный перевод с использованием рекуррентных нейронных сетей\n","\n","__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n","\n","Материалы:\n","* Deep Learning with PyTorch (2020) Авторы: Eli Stevens, Luca Antiga, Thomas Viehmann\n","* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#the-seq2seq-model\n","* https://www.adeveloperdiary.com/data-science/deep-learning/nlp/machine-translation-recurrent-neural-network-pytorch/"]},{"cell_type":"markdown","metadata":{"id":"c9ecd663"},"source":["## Задачи для совместного разбора"]},{"cell_type":"markdown","metadata":{"id":"05433855"},"source":["1\\. Рассмотрите пример архитектуры Encoder-Decoder с использованием RNN. Обсудите концепцию teacher forcing."]},{"cell_type":"code","source":["import torch as th\n","import torch.nn as nn"],"metadata":{"id":"HfFAL6gPrLZC","executionInfo":{"status":"ok","timestamp":1700613403118,"user_tz":-180,"elapsed":266,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":794,"outputs":[]},{"cell_type":"code","source":["n_ru_tokens = 1000\n","batch_size = 16\n","ru_seq_len = 15\n","n_en_tokens = 500\n","en_seq_len = 10\n","\n","ru = th.randint(0, n_ru_tokens, size=(batch_size, ru_seq_len))\n","en = th.randint(0, n_en_tokens, size=(batch_size, en_seq_len))"],"metadata":{"id":"SvmriPBurXrB","executionInfo":{"status":"ok","timestamp":1700613403404,"user_tz":-180,"elapsed":4,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":795,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, embedding_dim, hidden_size):\n","      super().__init__()\n","      self.emb = nn.Embedding(\n","          num_embeddings=n_ru_tokens,\n","          embedding_dim=embedding_dim,\n","          padding_idx=0\n","      )\n","      self.dropout = nn.Dropout(p=0.5)\n","      self.rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n","\n","  def forward(self, X):\n","    out = self.emb(X) # batch x seq x emb_size\n","    out = self.dropout(out)\n","    _, h = self.rnn(out) # out: batch x seq x hidden_size\n","    return h # 1 x batch x hidden_size"],"metadata":{"id":"1uwR4gJlrubF","executionInfo":{"status":"ok","timestamp":1700613403404,"user_tz":-180,"elapsed":4,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":796,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 100\n","encoder_hidden_size = 300\n","\n","encoder = Encoder(embedding_dim, encoder_hidden_size)\n","\n","encoder_output = encoder(ru)"],"metadata":{"id":"A2mQsa1hs-dg","executionInfo":{"status":"ok","timestamp":1700613403404,"user_tz":-180,"elapsed":3,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":797,"outputs":[]},{"cell_type":"code","source":["encoder_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEnVbLWQtUXe","executionInfo":{"status":"ok","timestamp":1700613403404,"user_tz":-180,"elapsed":3,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"b49b0b81-c09b-4e81-8c70-5b4ba70e372a"},"execution_count":798,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 16, 300])"]},"metadata":{},"execution_count":798}]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","  def __init__(self, embedding_dim, decoder_hidden_size):\n","    super().__init__()\n","    self.emb = nn.Embedding(\n","          num_embeddings=n_en_tokens,\n","          embedding_dim=embedding_dim,\n","          padding_idx=0\n","    )\n","    self.rnn = nn.GRUCell(embedding_dim, decoder_hidden_size)\n","    self.fc = nn.Linear(decoder_hidden_size, n_en_tokens)\n","\n","  def forward(self, encoder_output, labels):\n","    # labels: batch x seq_len - считаем, что в 0 столбце SOS\n","    # encoder_output: 1 x batch x encoder_hidden_size\n","    seq_len = labels.size(1)\n","    input_tokens = labels[:, 0]\n","    decoder_hidden = encoder_output[0]\n","    for _ in range(1, seq_len):\n","      out = self.emb(input_tokens).relu() # batch x emb_size\n","      decoder_hidden = self.rnn(out, decoder_hidden) # batch x dec_hidden\n","      out = self.fc(decoder_hidden) # batch x n_en_tokens\n","\n","      # teacher forcing\n","      input_tokens = out.argmax(dim=1).detach()\n","      # ...\n","\n","\n","    # вернуть прогнозы для каждого эл-та последовательности\n","    # batch x seq x n_en_token\n","    return ..."],"metadata":{"id":"ypiaR5DOtYCM","executionInfo":{"status":"ok","timestamp":1700613403787,"user_tz":-180,"elapsed":385,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":799,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(embedding_dim=100, decoder_hidden_size=300)\n","decoder(encoder_output, en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQga1gGsvxbZ","executionInfo":{"status":"ok","timestamp":1700613403787,"user_tz":-180,"elapsed":31,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"f06467bc-9b24-4924-e273-1d743b698558"},"execution_count":800,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":800}]},{"cell_type":"markdown","metadata":{"id":"4d7b6d63"},"source":["## Задачи для самостоятельного решения"]},{"cell_type":"markdown","metadata":{"id":"20525395"},"source":["<p class=\"task\" id=\"1\"></p>\n","\n","1\\. Считайте файлы `RuBQ_2.0_train.json` (обучающее множество) и `RuBQ_2.0_test.json` (тестовое множество). Для каждого файла создайте по списка: список предложений на русском языке и список предложений на английском языке. Выведите на экран количество примеров в обучающей и тестовой выборке.\n","\n","- [x] Проверено на семинаре"]},{"cell_type":"code","source":["import json\n","with open('/content/drive/MyDrive/пм21_финашка/3 курс/NLP/04_rnn/RuBQ_2.0_test.json') as json_file:\n","    data_test = json.load(json_file)\n","\n","with open('/content/drive/MyDrive/пм21_финашка/3 курс/NLP/04_rnn/RuBQ_2.0_train.json') as json_file:\n","    data_train = json.load(json_file)\n","\n","data_train[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmr8Cnooz9ZU","executionInfo":{"status":"ok","timestamp":1700613403787,"user_tz":-180,"elapsed":29,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"2795bffb-ff3b-4936-fd28-ed7ca339bd9f"},"execution_count":801,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'uid': 0,\n","  'question_text': 'Что может вызвать цунами?',\n","  'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q8070 wdt:P828 ?answer\\n}',\n","  'answer_text': 'Землетрясение',\n","  'question_uris': ['http://www.wikidata.org/entity/Q8070'],\n","  'question_props': ['wdt:P828'],\n","  'answers': [{'type': 'uri',\n","    'label': 'землетрясение',\n","    'value': 'http://www.wikidata.org/entity/Q7944',\n","    'wd_names': {'ru': ['землетрясение', 'җир тетрәве'],\n","     'en': ['seism',\n","      'earthquake',\n","      'seismic activity',\n","      'fore shocks',\n","      'tremor',\n","      'earthquakes',\n","      'earth quake',\n","      'earthtemblor',\n","      'foreshock',\n","      'aftershock',\n","      'quake',\n","      'temblor',\n","      'earth temblor',\n","      'foreshocks',\n","      'after shocks',\n","      'earth quakes',\n","      'after shock',\n","      'earthtremor',\n","      'convulsion',\n","      'earth tremor',\n","      'shock',\n","      'fore shock',\n","      'aftershocks']},\n","    'wp_names': ['землетрясениям']},\n","   {'type': 'uri',\n","    'label': 'метеорит',\n","    'value': 'http://www.wikidata.org/entity/Q60186',\n","    'wd_names': {'ru': ['метеорит', 'Метеориты', 'Аэролиты'],\n","     'en': ['shooting star', 'meteorite']},\n","    'wp_names': []},\n","   {'type': 'uri',\n","    'label': 'оползень',\n","    'value': 'http://www.wikidata.org/entity/Q167903',\n","    'wd_names': {'ru': ['оползень', 'оползни'],\n","     'en': ['Rock avalanche', 'landslide', 'landslip']},\n","    'wp_names': ['оползни', 'оползнями']},\n","   {'type': 'uri',\n","    'label': 'Проект Seal',\n","    'value': 'http://www.wikidata.org/entity/Q2580904',\n","    'wd_names': {'ru': ['Проект Seal'], 'en': ['tsunami bomb']},\n","    'wp_names': []},\n","   {'type': 'uri',\n","    'label': 'подводный оползень',\n","    'value': 'http://www.wikidata.org/entity/Q5975740',\n","    'wd_names': {'ru': [],\n","     'en': ['undersea landslide',\n","      'submarine landslide',\n","      'underwater landslide']},\n","    'wp_names': []},\n","   {'type': 'uri',\n","    'label': 'извержение вулкана',\n","    'value': 'http://www.wikidata.org/entity/Q7692360',\n","    'wd_names': {'ru': ['Фреатическое извержение',\n","      'Вулканические извержения',\n","      'Стромболианское извержение',\n","      'извержение вулкана',\n","      'Гавайское извержение',\n","      'Газовое извержение',\n","      'Вулканическое извержение',\n","      'Пелейское извержение'],\n","     'en': ['volcano eruption', 'volcanic eruption', 'eruption']},\n","    'wp_names': ['извержения вулкана']}],\n","  'paragraphs_uids': {'with_answer': [35622],\n","   'all_related': [35622,\n","    35623,\n","    35624,\n","    35625,\n","    35626,\n","    35632,\n","    35633,\n","    35634,\n","    35635,\n","    35636,\n","    35637,\n","    35638,\n","    35639,\n","    35640,\n","    35641,\n","    35642,\n","    35643,\n","    35644,\n","    35645,\n","    35646,\n","    35647,\n","    35648,\n","    35649,\n","    35650,\n","    35651]},\n","  'tags': ['1-hop'],\n","  'RuBQ_version': '1.0',\n","  'question_eng': 'What can cause a tsunami?'},\n"," {'uid': 1,\n","  'question_text': 'Кто написал роман «Хижина дяди Тома»?',\n","  'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q2222 wdt:P50 ?answer\\n}',\n","  'answer_text': 'Г. Бичер-Стоу',\n","  'question_uris': ['http://www.wikidata.org/entity/Q2222'],\n","  'question_props': ['wdt:P50'],\n","  'answers': [{'type': 'uri',\n","    'label': 'Гарриет Бичер-Стоу',\n","    'value': 'http://www.wikidata.org/entity/Q102513',\n","    'wd_names': {'ru': ['Стоу Гарриет Бичер',\n","      'Бичер-Стоу Гарриет',\n","      'Гарриет Бичер-Стоу',\n","      'Бичер Стоу',\n","      'Гарриет Стоу',\n","      'Бичер-Стоу',\n","      'Бичер-Стоу Г.',\n","      'Бичер-Стоу Гарриэт',\n","      'Гарриет Элизабет Бичер-Стоу',\n","      'Стоу, Гарриет Бичер',\n","      'Бичер-Стоу, Гарриэт',\n","      'Гарриет Бичер Стоу'],\n","     'en': ['Christopher Crowfield',\n","      'Harriet Elizabeth Beecher Stowe',\n","      'Enrieta Elizabeth Beecher Stowe',\n","      'Harriet Beecher Stowe']},\n","    'wp_names': ['Гарриет Бичер-Стоу']}],\n","  'paragraphs_uids': {'with_answer': [35652],\n","   'all_related': [35652,\n","    35653,\n","    35654,\n","    35655,\n","    35656,\n","    35657,\n","    35658,\n","    35659,\n","    35660,\n","    35661,\n","    35662,\n","    35663,\n","    35664,\n","    35665,\n","    35666,\n","    35667,\n","    35668,\n","    35669,\n","    35670,\n","    35671,\n","    35672,\n","    35673,\n","    35674,\n","    35675]},\n","  'tags': ['1-hop'],\n","  'RuBQ_version': '1.0',\n","  'question_eng': 'Who wrote the novel \"uncle Tom\\'s Cabin\"?'},\n"," {'uid': 2,\n","  'question_text': 'Кто автор пьесы «Ромео и Джульетта»?',\n","  'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q83186 wdt:P50 ?answer\\n}',\n","  'answer_text': 'Шекспир',\n","  'question_uris': ['http://www.wikidata.org/entity/Q83186'],\n","  'question_props': ['wdt:P50'],\n","  'answers': [{'type': 'uri',\n","    'label': 'Уильям Шекспир',\n","    'value': 'http://www.wikidata.org/entity/Q692',\n","    'wd_names': {'ru': ['Уильям Шекспир',\n","      'Шекспир, Уильям',\n","      'Вильям Шекспир',\n","      'Шекспир'],\n","     'en': ['The Bard',\n","      'Swan of Avon',\n","      'The Bard of Avon',\n","      'Bard of Avon',\n","      'Shakespeare',\n","      'William Shake‐ſpeare',\n","      'Shakspeare',\n","      'Shackspeare',\n","      'William Shakespeare',\n","      'William Shakspere',\n","      'Shakespere',\n","      'Shakespear']},\n","    'wp_names': ['Уильяма Шекспира']}],\n","  'paragraphs_uids': {'with_answer': [35676, 35677],\n","   'all_related': [35676,\n","    35677,\n","    35678,\n","    35679,\n","    35680,\n","    35681,\n","    35682,\n","    35683,\n","    35684,\n","    35685,\n","    35686,\n","    35687,\n","    35688,\n","    35689,\n","    35690,\n","    35691,\n","    35692,\n","    35693,\n","    35694,\n","    35695,\n","    35696,\n","    35697,\n","    35698,\n","    35699,\n","    35700]},\n","  'tags': ['1-hop'],\n","  'RuBQ_version': '1.0',\n","  'question_eng': 'Who is the author of the play \"Romeo and Juliet\"?'},\n"," {'uid': 3,\n","  'question_text': 'Как называется столица Румынии?',\n","  'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q218 wdt:P36 ?answer\\n}',\n","  'answer_text': 'Бухарест',\n","  'question_uris': ['http://www.wikidata.org/entity/Q218'],\n","  'question_props': ['wdt:P36'],\n","  'answers': [{'type': 'uri',\n","    'label': 'Бухарест',\n","    'value': 'http://www.wikidata.org/entity/Q19660',\n","    'wd_names': {'ru': ['Букурешти', 'Бухарест'],\n","     'en': ['Paris of the East',\n","      'București',\n","      'Bucureşti',\n","      'Little Paris',\n","      'Bucharest',\n","      'Bucuresti']},\n","    'wp_names': ['муниципий Бухарест']}],\n","  'paragraphs_uids': {'with_answer': [35702, 35703],\n","   'all_related': [35712,\n","    35713,\n","    35714,\n","    35715,\n","    35716,\n","    35717,\n","    35718,\n","    35719,\n","    35720,\n","    35721,\n","    35722,\n","    35723,\n","    35724,\n","    35725,\n","    35701,\n","    35702,\n","    35703,\n","    35704,\n","    35705,\n","    35706,\n","    35707,\n","    35708,\n","    35709,\n","    35710,\n","    35711]},\n","  'tags': ['1-hop'],\n","  'RuBQ_version': '1.0',\n","  'question_eng': 'What is the name of the capital of Romania?'},\n"," {'uid': 5,\n","  'question_text': 'На каком инструменте играл Джимми Хендрикс?',\n","  'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q5928 wdt:P1303 ?answer\\n}',\n","  'answer_text': 'Гитара',\n","  'question_uris': ['http://www.wikidata.org/entity/Q5928'],\n","  'question_props': ['wdt:P1303'],\n","  'answers': [{'type': 'uri',\n","    'label': 'гитара',\n","    'value': 'http://www.wikidata.org/entity/Q6607',\n","    'wd_names': {'ru': ['Семиструнная гитара',\n","      'Шестиструнная гитара',\n","      'гитара'],\n","     'en': ['guitar']},\n","    'wp_names': ['гитаре']},\n","   {'type': 'uri',\n","    'label': 'казу',\n","    'value': 'http://www.wikidata.org/entity/Q483994',\n","    'wd_names': {'ru': ['казу'], 'en': ['kazoo']},\n","    'wp_names': []},\n","   {'type': 'uri',\n","    'label': 'колокольчики',\n","    'value': 'http://www.wikidata.org/entity/Q626035',\n","    'wd_names': {'ru': ['Глокеншпиль', 'колокольчики'],\n","     'en': ['glockenspiel']},\n","    'wp_names': ['колокольчиках']},\n","   {'type': 'uri',\n","    'label': 'вокалист',\n","    'value': 'http://www.wikidata.org/entity/Q2643890',\n","    'wd_names': {'ru': ['вокалистка', 'вокалист', 'вокал'],\n","     'en': ['vocalist']},\n","    'wp_names': []},\n","   {'type': 'uri',\n","    'label': 'вокал',\n","    'value': 'http://www.wikidata.org/entity/Q17172850',\n","    'wd_names': {'ru': ['голос', 'певческий голос', 'вокал'],\n","     'en': ['voice', 'singing voice', 'vocals']},\n","    'wp_names': []}],\n","  'paragraphs_uids': {'with_answer': [35728, 35727],\n","   'all_related': [35726,\n","    35727,\n","    35728,\n","    35729,\n","    35730,\n","    35731,\n","    35732,\n","    35733,\n","    35734,\n","    35735,\n","    35741,\n","    35742,\n","    35743,\n","    35744,\n","    35745,\n","    35746,\n","    35747,\n","    35748,\n","    35749,\n","    35750,\n","    35751,\n","    35752,\n","    35753,\n","    35754,\n","    35755]},\n","  'tags': ['1-hop'],\n","  'RuBQ_version': '1.0',\n","  'question_eng': 'What instrument did Jimi Hendrix play?'}]"]},"metadata":{},"execution_count":801}]},{"cell_type":"code","source":["train_ru = []\n","train_en = []\n","for i in data_train:\n","  train_ru.append(i['question_text'])\n","  train_en.append(i['question_eng'])\n","\n","test_ru = []\n","test_en = []\n","for i in data_test:\n","  test_ru.append(i['question_text'])\n","  test_en.append(i['question_eng'])"],"metadata":{"id":"6MP_h8THyuYy","executionInfo":{"status":"ok","timestamp":1700613403787,"user_tz":-180,"elapsed":24,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":802,"outputs":[]},{"cell_type":"code","source":["train_ru[:10], train_en[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0g7P9olf1RI9","executionInfo":{"status":"ok","timestamp":1700613403788,"user_tz":-180,"elapsed":25,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"f6f23c05-480e-4b2f-a3df-9eddb9da1abe"},"execution_count":803,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['Что может вызвать цунами?',\n","  'Кто написал роман «Хижина дяди Тома»?',\n","  'Кто автор пьесы «Ромео и Джульетта»?',\n","  'Как называется столица Румынии?',\n","  'На каком инструменте играл Джимми Хендрикс?',\n","  'Какой стране принадлежит остров Таити?',\n","  'Кто создал Зимний дворец в Санкт-Петербурге?',\n","  'Кто режиссер фильма \"Бриллиантовая рука\"?',\n","  'Какой стране принадлежат Канарские острова?',\n","  'Какой географический объект называется Лимпопо?'],\n"," ['What can cause a tsunami?',\n","  'Who wrote the novel \"uncle Tom\\'s Cabin\"?',\n","  'Who is the author of the play \"Romeo and Juliet\"?',\n","  'What is the name of the capital of Romania?',\n","  'What instrument did Jimi Hendrix play?',\n","  'What country owns the island of Tahiti?',\n","  'Who created the Winter Palace in St. Petersburg?',\n","  'Who is the Director of the film \"diamond hand\"?',\n","  'Which country does the Canary Islands belong to?',\n","  'What geographical feature is called Limpopo?'])"]},"metadata":{},"execution_count":803}]},{"cell_type":"code","source":["len(train_ru), len(test_ru)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"494l-NjwQeGO","executionInfo":{"status":"ok","timestamp":1700613403788,"user_tz":-180,"elapsed":14,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"4675b2a5-d0ea-44bf-d997-7c37d77d5d12"},"execution_count":804,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2330, 580)"]},"metadata":{},"execution_count":804}]},{"cell_type":"code","source":["len(train_ru), len(train_en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PD-YPtZbsTzd","executionInfo":{"status":"ok","timestamp":1700613403788,"user_tz":-180,"elapsed":10,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"02efc2e6-c98a-43cb-c6c9-25e20fd9157a"},"execution_count":805,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2330, 2330)"]},"metadata":{},"execution_count":805}]},{"cell_type":"markdown","metadata":{"id":"51d8edd3"},"source":["<p class=\"task\" id=\"2\"></p>\n","\n","2\\. Создайте два Vocab на основе загруженных данных: `ru_vocab` для слов на русском языке и `en_vocab` для слов на английском языке (словари создаются на основе обучающего множества). Добавьте в словари специальные токены `<PAD>`, `<SOS>`, `<EOS>`. Выведите на экран количество токенов в полученных словарях. Выведите на экран максимальное кол-во слов в предложениях на русском языке и в предложениях на английском языке (в обучающей выборке).\n","\n","- [x] Проверено на семинаре"]},{"cell_type":"code","source":["from torchtext.vocab import Vocab\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9X4x2CjX1aIj","executionInfo":{"status":"ok","timestamp":1700613403789,"user_tz":-180,"elapsed":10,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"4f077e0e-73e9-45b3-a9b6-df85de6bb6d7"},"execution_count":806,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":806}]},{"cell_type":"code","source":["import re\n","pattern_ru = re.compile(r'[^А-Яа-яёЁ]+')\n","pattern_en = re.compile(r'[^A-Za-z]+')"],"metadata":{"id":"XairDBom3Gz2","executionInfo":{"status":"ok","timestamp":1700613403789,"user_tz":-180,"elapsed":8,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":807,"outputs":[]},{"cell_type":"code","source":["def del_punctuation(df, pattern):\n","  res = []\n","  for i in df:\n","    stroka = re.sub(pattern,' ', i)\n","    res.append(word_tokenize(stroka))\n","\n","  return res"],"metadata":{"id":"lCU5RG5a6fGs","executionInfo":{"status":"ok","timestamp":1700613403789,"user_tz":-180,"elapsed":8,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":808,"outputs":[]},{"cell_type":"code","source":["corpus_ru = del_punctuation(train_ru, pattern_ru)\n","corpus_en = del_punctuation(train_en, pattern_en)\n","\n","corpus_ru_test = del_punctuation(test_ru, pattern_ru)\n","corpus_en_test = del_punctuation(test_en, pattern_en)"],"metadata":{"id":"UtrnIvqo6fBK","executionInfo":{"status":"ok","timestamp":1700613404411,"user_tz":-180,"elapsed":629,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":809,"outputs":[]},{"cell_type":"code","source":["corpus_ru[:10], corpus_en[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfdmY9924_4V","executionInfo":{"status":"ok","timestamp":1700613404412,"user_tz":-180,"elapsed":8,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"620a6222-ac5f-4bb7-9619-0cbdf7e6e2cd"},"execution_count":810,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([['Что', 'может', 'вызвать', 'цунами'],\n","  ['Кто', 'написал', 'роман', 'Хижина', 'дяди', 'Тома'],\n","  ['Кто', 'автор', 'пьесы', 'Ромео', 'и', 'Джульетта'],\n","  ['Как', 'называется', 'столица', 'Румынии'],\n","  ['На', 'каком', 'инструменте', 'играл', 'Джимми', 'Хендрикс'],\n","  ['Какой', 'стране', 'принадлежит', 'остров', 'Таити'],\n","  ['Кто', 'создал', 'Зимний', 'дворец', 'в', 'Санкт', 'Петербурге'],\n","  ['Кто', 'режиссер', 'фильма', 'Бриллиантовая', 'рука'],\n","  ['Какой', 'стране', 'принадлежат', 'Канарские', 'острова'],\n","  ['Какой', 'географический', 'объект', 'называется', 'Лимпопо']],\n"," [['What', 'can', 'cause', 'a', 'tsunami'],\n","  ['Who', 'wrote', 'the', 'novel', 'uncle', 'Tom', 's', 'Cabin'],\n","  ['Who',\n","   'is',\n","   'the',\n","   'author',\n","   'of',\n","   'the',\n","   'play',\n","   'Romeo',\n","   'and',\n","   'Juliet'],\n","  ['What', 'is', 'the', 'name', 'of', 'the', 'capital', 'of', 'Romania'],\n","  ['What', 'instrument', 'did', 'Jimi', 'Hendrix', 'play'],\n","  ['What', 'country', 'owns', 'the', 'island', 'of', 'Tahiti'],\n","  ['Who', 'created', 'the', 'Winter', 'Palace', 'in', 'St', 'Petersburg'],\n","  ['Who', 'is', 'the', 'Director', 'of', 'the', 'film', 'diamond', 'hand'],\n","  ['Which', 'country', 'does', 'the', 'Canary', 'Islands', 'belong', 'to'],\n","  ['What', 'geographical', 'feature', 'is', 'called', 'Limpopo']])"]},"metadata":{},"execution_count":810}]},{"cell_type":"code","source":["len(corpus_ru), len(corpus_en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSYAmd6XscuP","executionInfo":{"status":"ok","timestamp":1700613404750,"user_tz":-180,"elapsed":346,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"4f008160-a910-42d4-fd09-7b0de8d0a859"},"execution_count":811,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2330, 2330)"]},"metadata":{},"execution_count":811}]},{"cell_type":"code","source":["token = ['<PAD>', '<SOS>', '<EOS>']\n","\n","vocab_ru = build_vocab_from_iterator(\n","    corpus_ru,\n","    specials = token\n",")\n","\n","vocab_en = build_vocab_from_iterator(\n","    corpus_en,\n","    specials = token\n",")\n","\n","len(vocab_ru), len(vocab_en)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"px-Bh6TZ5kcx","executionInfo":{"status":"ok","timestamp":1700613404751,"user_tz":-180,"elapsed":4,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"e6ed2975-3cf0-4948-e8c0-8f14cc4f06a4"},"execution_count":812,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5959, 4348)"]},"metadata":{},"execution_count":812}]},{"cell_type":"code","source":["token = ['<PAD>', '<SOS>', '<EOS>']\n","\n","vocab_ru_test = build_vocab_from_iterator(\n","    corpus_ru_test,\n","    specials = token\n",")\n","\n","vocab_en_test = build_vocab_from_iterator(\n","    corpus_en_test,\n","    specials = token\n",")\n","\n","len(vocab_ru_test), len(vocab_en_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4htcX5qKePhc","executionInfo":{"status":"ok","timestamp":1700613405058,"user_tz":-180,"elapsed":310,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"2770ca46-b4c0-4685-aeef-eb05a9cfef55"},"execution_count":813,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1973, 1598)"]},"metadata":{},"execution_count":813}]},{"cell_type":"code","source":["# vocab_ru.get_stoi()"],"metadata":{"id":"s2R_gyUc5533","executionInfo":{"status":"ok","timestamp":1700613405058,"user_tz":-180,"elapsed":7,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":814,"outputs":[]},{"cell_type":"code","source":["max([len(i) for i in corpus_ru]), max([len(i) for i in corpus_en])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ncgyjkCPM6Fv","executionInfo":{"status":"ok","timestamp":1700613405059,"user_tz":-180,"elapsed":8,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"80659241-6493-48fb-d705-20cb88100da5"},"execution_count":815,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25, 31)"]},"metadata":{},"execution_count":815}]},{"cell_type":"code","source":["maxlen = max(max([len(i) for i in corpus_ru]), max([len(i) for i in corpus_en])) +2\n","maxlen"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hpo3SbeGwV4K","executionInfo":{"status":"ok","timestamp":1700613405059,"user_tz":-180,"elapsed":6,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"4bc3c6d2-c3f7-48ea-d888-b8a4fb3f69e1"},"execution_count":816,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33"]},"metadata":{},"execution_count":816}]},{"cell_type":"markdown","metadata":{"id":"a1d666a1"},"source":["<p class=\"task\" id=\"3\"></p>\n","\n","3\\. Создайте класс `RuEnDataset`. Реализуйте `__getitem__` таким образом, чтобы он возвращал кортеж `(x, y)`, где x - это набор индексов токенов для предложений на русском языке, а `y` - набор индексов токенов для предложений на английском языке. Используя преобразования, сделайте длины наборов индексов одинаковой фиксированной длины, добавьте в начало каждого набора индекс `<SOS>`, а в конец - индекс токена `<EOS>`. Создайте датасет для обучающей и тестовой выборки.\n","\n","- [ ] Проверено на семинаре *(по-другому сделала)*"]},{"cell_type":"code","source":["import torchtext.transforms as T\n","\n","class RuEnDataset:\n","\n","  def __init__(self, x, y, vocab_ru, vocab_en, maxlen):\n","    self.x = x  # corpus_ru\n","    self.y = y  # corpus_en\n","    self.vocab_ru = vocab_ru\n","    self.vocab_en = vocab_en\n","    self.maxlen = maxlen\n","    self.transform_ru = self.transform(self.vocab_ru)\n","    self.transform_en = self.transform(self.vocab_en)\n","\n","  def transform(self, vocab):\n","    transforms = T.Sequential(\n","        T.VocabTransform(vocab),\n","        T.AddToken(token = vocab.get_stoi()['<SOS>'], begin = True),   # в начало\n","        T.AddToken(token = vocab.get_stoi()['<EOS>'], begin = False),  # в конец\n","        T.ToTensor(padding_value = vocab.get_stoi()['<PAD>']) ,  # заполнение 0\n","        T.PadTransform(max_length = self.maxlen, pad_value =  vocab.get_stoi()['<PAD>'])  # заполнение до фиксированной длины\n","    )\n","    return transforms\n","\n","\n","  def __getitem__(self, idx):\n","\n","    if type(idx) == int:\n","      idx = slice(idx, idx+1)\n","\n","    self.x = self.x[idx]\n","    self.y = self.y[idx]\n","    ru = self.transform_ru(self.x)\n","    en = self.transform_en(self.y)\n","\n","    return ru, en\n","\n"],"metadata":{"id":"1MeLxqBgM-Gu","executionInfo":{"status":"ok","timestamp":1700613405059,"user_tz":-180,"elapsed":5,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":817,"outputs":[]},{"cell_type":"code","source":["RuEnDataset(x = corpus_ru, y = corpus_en, vocab_ru = vocab_ru, vocab_en = vocab_en, maxlen = maxlen)[4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJhYPsLhcbNe","executionInfo":{"status":"ok","timestamp":1700613405320,"user_tz":-180,"elapsed":266,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"48da2a07-ce8c-4d9a-8907-e2622cadf01c"},"execution_count":818,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[   1,   20,    4,  225,   90, 1972, 3155,    2,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0]]),\n"," tensor([[   1,    6,  191,   13, 2117, 2033,   46,    2,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0]]))"]},"metadata":{},"execution_count":818}]},{"cell_type":"code","source":["# corpus_x = [\n","#         vocab_ru.lookup_indices(t)\n","#         for t in corpus_ru\n","#     ]\n","# # corpus_x\n","\n","# transform = T.ToTensor(padding_value = 0)\n","# res1 = transform(corpus_x)\n","# res1[0]"],"metadata":{"id":"KDTINmv4aEkP","executionInfo":{"status":"ok","timestamp":1700613405321,"user_tz":-180,"elapsed":4,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":819,"outputs":[]},{"cell_type":"code","source":["train_ds = RuEnDataset(x = corpus_ru, y = corpus_en, vocab_ru = vocab_ru, vocab_en = vocab_en, maxlen = maxlen)[:]\n","test_ds = RuEnDataset(x = corpus_ru_test, y = corpus_en_test, vocab_ru = vocab_ru_test, vocab_en = vocab_en_test, maxlen = maxlen)[:]"],"metadata":{"id":"FkO4EvQ16QkN","executionInfo":{"status":"ok","timestamp":1700613405649,"user_tz":-180,"elapsed":331,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":820,"outputs":[]},{"cell_type":"code","source":["train_ds[0].shape, test_ds[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fj2YZiDx6QiF","executionInfo":{"status":"ok","timestamp":1700613405649,"user_tz":-180,"elapsed":16,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"57ff5e62-08e9-4b32-ac9f-8ed69268bbf6"},"execution_count":821,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2330, 33]), torch.Size([580, 33]))"]},"metadata":{},"execution_count":821}]},{"cell_type":"markdown","metadata":{"id":"ca51f9bd"},"source":["<p class=\"task\" id=\"4\"></p>\n","\n","4\\. Опишите модель `Encoder`, которая возвращает скрытое состояние рекуррентного слоя в соотстветствии со следующей схемой. Пропустите через эту модель первые 16 предложений на русском языке и выведите размер полученного результата на экран. Результатом должен являться тензор размера `1 x batch_size x hidden_dim` (если используется один однонаправленный рекуррентный слой и `batch_first=True`).\n","\n","* количество эмбеддингов равно количеству слов на русском языке;\n","* размерность эмбеддингов выберите самостоятельно;\n","* при создании слоя эмбеддингов укажите `padding_idx`;\n","* размер скрытого состояния рекуррентного слоя выберите самостоятельно.\n","\n","![encoder](https://i0.wp.com/www.adeveloperdiary.com/wp-content/uploads/2020/10/Machine-Translation-using-Recurrent-Neural-Network-and-PyTorch-adeveloperdiary.com-1.png?w=815&ssl=1)\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"code","source":["# Переносим данные на GPU, если доступен\n","device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7X8FZNitbBz","executionInfo":{"status":"ok","timestamp":1700613405649,"user_tz":-180,"elapsed":15,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"f6908b58-ea90-409a-a5e3-6b088644fbb6"},"execution_count":822,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":822}]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, embedding_dim, hidden_size):\n","      super().__init__()\n","      self.emb = nn.Embedding(\n","          num_embeddings = len(vocab_ru),\n","          embedding_dim=embedding_dim,\n","          padding_idx=0\n","      )\n","      # self.dropout = nn.Dropout(p=0.5)\n","      self.rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n","\n","  def forward(self, X):\n","    out = self.emb(X) # batch x seq x emb_size\n","    # out = self.dropout(out)\n","    _, h = self.rnn(out) # out: batch x seq x hidden_size\n","    return h # 1 x batch x hidden_size"],"metadata":{"id":"B9Dh5-bX9EKv","executionInfo":{"status":"ok","timestamp":1700613405649,"user_tz":-180,"elapsed":14,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":823,"outputs":[]},{"cell_type":"code","source":["model = Encoder(embedding_dim = 150, hidden_size = 64)"],"metadata":{"id":"GuKrP3ABflz_","executionInfo":{"status":"ok","timestamp":1700613405649,"user_tz":-180,"elapsed":14,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":824,"outputs":[]},{"cell_type":"code","source":["train_ds[0][:16]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUfY5cJNhNim","executionInfo":{"status":"ok","timestamp":1700613405649,"user_tz":-180,"elapsed":14,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"3418ee81-3795-4200-9687-93d55e1fe09b"},"execution_count":825,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   1,   30,  722, 3637, 5857,    2,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    5,   28,  234, 3161, 3894, 1055,    2,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    5,   61,  778, 1021,   16, 1983,    2,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   14,   29,   65, 2805,    2,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   20,    4,  225,   90, 1972, 3155,    2,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    7,   21,   49,  104, 2981,    2,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    5,   95,  578,  219,    6,   99,  184,    2,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    5,  176,   53,  560, 1406,    2,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    7,   21,  199, 2168,  292,    2,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    7, 3682,  486,   29, 2344,    2,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   24, 5423,  261,  453, 5629,   19,  279, 1293, 3883, 3402,   15,\n","         2547,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1, 1000,    8, 5900, 4059, 5346, 4006,    2,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    3,    8,   21,   89, 4977,  692,    6, 3722,    2,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   69,  436,   52, 1473,  173, 1013,    3,    3,  127,    2,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   14,   31,  356, 1030, 1035,    2,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   14,   31,  238, 2002,    2,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0]])"]},"metadata":{},"execution_count":825}]},{"cell_type":"code","source":["encoder_output = model(train_ds[0][:16])\n","encoder_output.shape"],"metadata":{"executionInfo":{"status":"ok","timestamp":1700613405650,"user_tz":-180,"elapsed":13,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"gTJFVI_Fg52T","outputId":"7b814b91-972a-4f67-aa88-903d3a64cc41"},"execution_count":826,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 16, 64])"]},"metadata":{},"execution_count":826}]},{"cell_type":"markdown","metadata":{"id":"d94f101d"},"source":["<p class=\"task\" id=\"5\"></p>\n","\n","5\\. Опишите модель `Decoder`, которая возвращает прогноз (набор индексов слов на английском языке). Пропустите через эту модель тензор скрытых состояний кодировщика, полученный в предыдущей задачи, и выведите размер полученного результата на экран. Результатом должен являться тензор размера `batch_size x seq_len x n_en_words` (если используется один однонаправленный рекуррентный слой и `batch_first=True`).\n","\n","* количество эмбеддингов равно количеству слов на английском языке;\n","* размер выходного слоя равен количеству слов на английском языке;\n","* размерность эмбеддингов выберите самостоятельно;\n","* при создании слоя эмбеддингов укажите `padding_idx`;\n","* размер скрытого состояния рекуррентного слоя выберите самостоятельно.\n","\n","![decoder](https://i2.wp.com/www.adeveloperdiary.com/wp-content/uploads/2020/10/Machine-Translation-using-Recurrent-Neural-Network-and-PyTorch-adeveloperdiary.com-2.png?w=899&ssl=1)\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","  def __init__(self, embedding_dim, decoder_hidden_size):\n","    super().__init__()\n","    self.emb = nn.Embedding(\n","          num_embeddings=len(vocab_en),\n","          embedding_dim=embedding_dim,\n","          padding_idx=0\n","    )\n","    self.rnn = nn.GRUCell(embedding_dim, decoder_hidden_size)\n","    self.fc = nn.Linear(decoder_hidden_size, len(vocab_en))\n","\n","  def forward(self, encoder_output, labels):\n","    # labels: batch x seq_len - считаем, что в 0 столбце SOS\n","    # encoder_output: 1 x batch x encoder_hidden_size\n","    seq_len = labels.size(1)\n","    input_tokens = labels[:, 0]\n","    decoder_hidden = encoder_output[0]\n","\n","    outputs = []\n","    for _ in range( seq_len):\n","      out = self.emb(input_tokens).relu() # batch x emb_size\n","      decoder_hidden = self.rnn(out, decoder_hidden) # batch x dec_hidden\n","      out = self.fc(decoder_hidden) # batch x n_en_tokens\n","      outputs.append(out)\n","\n","      # teacher forcing\n","      # input_tokens = out.argmax(dim=1).detach()\n","      input_tokens = labels[:, _]  # входной токен для следующей итерации\n","\n","\n","\n","    # вернуть прогнозы для каждого эл-та последовательности\n","    # batch x seq x n_en_token\n","    return th.stack(outputs, dim=1)"],"metadata":{"id":"kZu4n9Ghhoid","executionInfo":{"status":"ok","timestamp":1700613405650,"user_tz":-180,"elapsed":11,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":827,"outputs":[]},{"cell_type":"code","source":["model = Decoder(embedding_dim = 150, decoder_hidden_size = 64)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1700613405650,"user_tz":-180,"elapsed":11,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"id":"7JKL0ws-nReg"},"execution_count":828,"outputs":[]},{"cell_type":"code","source":["train_ds[1][:16]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700613405650,"user_tz":-180,"elapsed":11,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"64fa3112-473c-4da1-daaf-4f8cf9d75679","id":"FznUhXGonReh"},"execution_count":829,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   1,    6,  157,  248,   25, 4258,    2,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    9,   52,    3,   64,  829,  503,   14, 1690,    2,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    9,    5,    3,   49,    4,    3,   46, 1053,   23,  962,    2,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6,    5,    3,   19,    4,    3,   29,    4, 2583,    2,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6,  191,   13, 2117, 2033,   46,    2,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6,   21,  192,    3,   97,    4, 2768,    2,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    9,   65,    3,  278,  183,    8,  110,  118,    2,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    9,    5,    3,   87,    4,    3,   32,  529,  755,    2,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   12,   21,   22,    3, 1702,  197,   51,   17,    2,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6, 1257, 1228,    5,   59, 2231,    2,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6,  228,   50, 3787,    3,  821,  366,    3,  120, 1551,   16,\n","            4, 2387,    7,   27,    2,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6, 4034,    5,  167,   17, 1310,    3, 4153,    4, 3354,    2,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,   10,   18,   21,   13,    3,  190,    4, 1989,   31,  697,    2,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6,   76,    4,   85,    7,   42,  103,  245,  184, 3596,    8,\n","            2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6,    7, 1066, 1071,   14,   80,   14,   19,    2,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   1,    6,    7, 1845,   14,  127,   14,   19,    2,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0]])"]},"metadata":{},"execution_count":829}]},{"cell_type":"code","source":["decoder_output = model(encoder_output, train_ds[1][:16])\n","decoder_output.shape"],"metadata":{"executionInfo":{"status":"ok","timestamp":1700613405650,"user_tz":-180,"elapsed":8,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de0216b1-1577-4e5a-a766-aa98f2ee585c","id":"VT4ASqE1nReh"},"execution_count":830,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 33, 4348])"]},"metadata":{},"execution_count":830}]},{"cell_type":"markdown","metadata":{"id":"da2f75c8"},"source":["<p class=\"task\" id=\"6\"></p>\n","\n","6\\. Объедините модели `Encoder` и `Decoder` в одну модель `EncoderDecoder`. Пропустите через эту модель первые 16 предложений на русском языке и выведите размер полученного результата на экран. Сделайте полученный результат двумерным, объединив две первые размерности: `batch_size * seq_len x n_en_words`. Выведите размерность полученного результата на экран.\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"code","source":["class EncoderDecoder(nn.Module):\n","\n","  def __init__(self, embedding_dim, hidden_size):\n","    super().__init__()\n","    self.encoder = Encoder(embedding_dim=embedding_dim, hidden_size=hidden_size)\n","    self.decoder = Decoder(embedding_dim=embedding_dim, decoder_hidden_size= hidden_size)\n","\n","  def forward(self, input_encoder, input_decoder):\n","    encoder_out = self.encoder(input_encoder)\n","    decoder_out = self.decoder(encoder_out, input_decoder)\n","\n","    return decoder_out.reshape(decoder_out.shape[0]*decoder_out.shape[1], decoder_out.shape[2])"],"metadata":{"id":"PtoaLhRJn1RE","executionInfo":{"status":"ok","timestamp":1700613405959,"user_tz":-180,"elapsed":313,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}}},"execution_count":831,"outputs":[]},{"cell_type":"code","source":["model = EncoderDecoder(embedding_dim=150, hidden_size= 32)\n","out = model.forward(train_ds[0][:16], train_ds[1][:16]); out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__J-H6wapF63","executionInfo":{"status":"ok","timestamp":1700613405959,"user_tz":-180,"elapsed":8,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"d89233d6-89e5-4766-d76e-7cd977c2ad59"},"execution_count":832,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0754, -0.2473,  0.0626,  ..., -0.1175,  0.2293, -0.0419],\n","        [ 0.0749, -0.3136,  0.0356,  ..., -0.1943,  0.1759, -0.0399],\n","        [ 0.0962,  0.0873,  0.0377,  ..., -0.1410, -0.0304,  0.5648],\n","        ...,\n","        [ 0.0753, -0.0096,  0.2062,  ...,  0.0426,  0.2399, -0.0433],\n","        [ 0.0753, -0.0096,  0.2062,  ...,  0.0426,  0.2399, -0.0433],\n","        [ 0.0753, -0.0096,  0.2062,  ...,  0.0426,  0.2399, -0.0433]],\n","       grad_fn=<ViewBackward0>)"]},"metadata":{},"execution_count":832}]},{"cell_type":"code","source":["out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ma6tmeU8p3N2","executionInfo":{"status":"ok","timestamp":1700613405959,"user_tz":-180,"elapsed":7,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"61c7ef8d-a7c1-4e0e-8eef-9676366ab424"},"execution_count":833,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([528, 4348])"]},"metadata":{},"execution_count":833}]},{"cell_type":"markdown","metadata":{"id":"ec784777"},"source":["<p class=\"task\" id=\"7\"></p>\n","\n","7\\. Настройте модель, решив задачу классификации на основе прогнозов модели `EncoderDecoder`. Игнорируйте токен `<PAD>` при расчете ошибки. Во время обучения выводите на экран значения функции потерь для эпохи (на обучающем множестве), значение accuracy по токенам (на обучающем множестве) и пример перевода, сгенерированного моделью. После завершения обучения посчитайте BLEU для тестового множества.\n","\n","- [ ] Проверено на семинаре"]},{"cell_type":"code","source":["train_ds[0].shape,train_ds[1].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKuuJCVNr5R9","executionInfo":{"status":"ok","timestamp":1700613405960,"user_tz":-180,"elapsed":7,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"e7d4ca88-569e-4202-cbbc-cfd9c537c1e6"},"execution_count":834,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2330, 33]), torch.Size([2330, 33]))"]},"metadata":{},"execution_count":834}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","train_dataset = TensorDataset(train_ds[0], train_ds[1])\n","test_dataset = TensorDataset(test_ds[0], test_ds[1])\n","\n","\n","loader_train = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n","loader_test = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n","next(iter(loader_train))\n","for ru_train, en_train in loader_train:\n","  print(ru_train.shape, en_train.shape)\n","  print(ru_train.view(-1))\n","  break"],"metadata":{"id":"rrjO3unpzAE_","executionInfo":{"status":"ok","timestamp":1700613408670,"user_tz":-180,"elapsed":313,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a911c9c9-fafd-4515-b4e6-b9562cf331c0"},"execution_count":835,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 33]) torch.Size([64, 33])\n","tensor([ 1,  5, 28,  ...,  0,  0,  0])\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import numpy as np\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = vocab_ru.get_stoi()['<PAD>'])\n","n_epochs = 100\n","model =  EncoderDecoder(embedding_dim=300, hidden_size= 32).to(device)\n","optimizer = optim.Adam(model.parameters(), lr = 0.01)\n","\n","losses = []\n","for epoch in range(n_epochs):\n","\n","  correct_train = 0  # правильно предсказанные\n","  total_train = 0\n","\n","  for ru_train, en_train in loader_train:\n","\n","    out = model(ru_train.to(device), en_train.to(device))\n","    # print(out)\n","    y_pred_train = th.argmax(out, dim=1)\n","    correct_train += (y_pred_train == en_train.view(-1)).sum().item()\n","    total_train += y_pred_train.shape[0]\n","\n","    loss = criterion(out, en_train.view(-1))\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","\n","  losses.append(loss.item())\n","  if (epoch+1)% 10 == 0 or epoch == 0:\n","    print(f'Epoch №{epoch+1}, loss --> {loss.item()}')\n","    print(f'Accuracy -- > {correct_train/total_train}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hP6-TlRAqieD","executionInfo":{"status":"ok","timestamp":1700613281750,"user_tz":-180,"elapsed":1630546,"user":{"displayName":"Настя Конева","userId":"03720402027676844470"}},"outputId":"e8e0f021-90d0-4483-eb6f-178859865e64"},"execution_count":789,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch №1, loss --> 4.7959065437316895\n","Accuracy -- > 0.09553908180517623\n","\n","Epoch №10, loss --> 3.0219926834106445\n","Accuracy -- > 0.15016256990505916\n","\n","Epoch №20, loss --> 2.86721134185791\n","Accuracy -- > 0.16021589283391857\n","\n","Epoch №30, loss --> 2.517676591873169\n","Accuracy -- > 0.16523605150214593\n","\n","Epoch №40, loss --> 2.5480916500091553\n","Accuracy -- > 0.1680972818311874\n","\n","Epoch №50, loss --> 2.14958119392395\n","Accuracy -- > 0.1718298868513461\n","\n","Epoch №60, loss --> 2.237186908721924\n","Accuracy -- > 0.1769931070360255\n","\n","Epoch №70, loss --> 2.0088024139404297\n","Accuracy -- > 0.18469241773962805\n","\n","Epoch №80, loss --> 1.9338449239730835\n","Accuracy -- > 0.18835999479776303\n","\n","Epoch №90, loss --> 2.0795071125030518\n","Accuracy -- > 0.1897645987774743\n","\n","Epoch №100, loss --> 2.092564821243286\n","Accuracy -- > 0.1795942255169723\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"66caa919"},"source":["## Обратная связь\n","- [ ] Хочу получить обратную связь по решению"]},{"cell_type":"code","source":[],"metadata":{"id":"DrwZjwN8v8KQ"},"execution_count":null,"outputs":[]}]}